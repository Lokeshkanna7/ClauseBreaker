{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5b32ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-text-splitters) (1.2.6)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lokesh\\anaconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b556150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 13:27:04.147 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\LOKESH\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -------------------------------\n",
    "# Streamlit Config\n",
    "# -------------------------------\n",
    "st.set_page_config(\n",
    "    page_title=\"Student Lease Break Advisor\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"Student Lease Break Advisor\")\n",
    "st.caption(\"Legal information assistant for students (not legal advice)\")\n",
    "\n",
    "# -------------------------------\n",
    "# Utility Functions\n",
    "# -------------------------------\n",
    "\n",
    "def get_splitter():\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"Section\", \"Clause\"]\n",
    "    )\n",
    "\n",
    "def load_lease(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "    docs = loader.load()\n",
    "    splitter = get_splitter()\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    for d in chunks:\n",
    "        d.metadata[\"source\"] = \"lease\"\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def load_laws(state):\n",
    "    laws = {\n",
    "        \"New York\": \"\"\"\n",
    "New York Real Property Law ยง227-e allows tenants to terminate a lease early under\n",
    "certain conditions such as financial hardship, employment relocation, or medical\n",
    "necessity, provided reasonable notice is given.\n",
    "\n",
    "New York Real Property Law ยง235-b establishes the Warranty of Habitability, requiring\n",
    "landlords to maintain safe and livable housing conditions. Failure to do so may\n",
    "justify lease termination.\n",
    "\"\"\",\n",
    "        \"California\": \"\"\"\n",
    "California Civil Code ยง1946 permits lease termination with proper written notice\n",
    "depending on lease type.\n",
    "\n",
    "California Civil Code ยง1941 requires landlords to maintain habitable living\n",
    "conditions. Failure to do so may justify lease termination.\n",
    "\"\"\"\n",
    "    }\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode=\"w\", suffix=\".txt\") as f:\n",
    "        f.write(laws[state])\n",
    "        law_path = f.name\n",
    "\n",
    "    loader = TextLoader(law_path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    splitter = get_splitter()\n",
    "    chunks = splitter.split_documents(docs)\n",
    "\n",
    "    for d in chunks:\n",
    "        d.metadata[\"source\"] = \"law\"\n",
    "        d.metadata[\"state\"] = state\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def build_vectorstore(docs):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/embedding-001\"\n",
    "    )\n",
    "    return FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "def generate_answer(question, lease_db, law_db):\n",
    "    lease_docs = lease_db.similarity_search(question, k=4)\n",
    "    law_docs = law_db.similarity_search(question, k=4)\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        [f\"[{d.metadata['source'].upper()}] {d.page_content}\"\n",
    "         for d in lease_docs + law_docs]\n",
    "    )\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal information assistant for students.\n",
    "You do NOT provide legal advice.\n",
    "You must base your response strictly on the provided lease clauses and state laws.\n",
    "If the information is insufficient, explicitly say so.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Respond with:\n",
    "1. Whether early termination may be legally allowed\n",
    "2. Required notice period (if specified)\n",
    "3. Potential penalties or risks\n",
    "4. Explicit citations (lease clause or statute)\n",
    "5. A clear legal disclaimer\n",
    "\"\"\"\n",
    "\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "# -------------------------------\n",
    "# Sidebar Inputs\n",
    "# -------------------------------\n",
    "state = st.sidebar.selectbox(\n",
    "    \"Select U.S. State\",\n",
    "    [\"New York\", \"California\"]\n",
    ")\n",
    "\n",
    "uploaded_file = st.sidebar.file_uploader(\n",
    "    \"Upload Lease (PDF or DOCX)\",\n",
    "    type=[\"pdf\", \"docx\"]\n",
    ")\n",
    "\n",
    "st.sidebar.markdown(\n",
    "    \"**Disclaimer:** This tool provides legal information, not legal advice.\"\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Main Interaction\n",
    "# -------------------------------\n",
    "question = st.chat_input(\"Ask a question about breaking your lease\")\n",
    "\n",
    "if uploaded_file:\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "        tmp.write(uploaded_file.read())\n",
    "        lease_path = tmp.name\n",
    "\n",
    "    with st.spinner(\"Processing lease document...\"):\n",
    "        lease_docs = load_lease(lease_path)\n",
    "        lease_db = build_vectorstore(lease_docs)\n",
    "\n",
    "    with st.spinner(\"Loading state tenant laws...\"):\n",
    "        law_docs = load_laws(state)\n",
    "        law_db = build_vectorstore(law_docs)\n",
    "\n",
    "    st.success(\"Lease and laws processed. You may ask questions.\")\n",
    "\n",
    "if question and uploaded_file:\n",
    "    with st.spinner(\"Analyzing your question...\"):\n",
    "        response = generate_answer(question, lease_db, law_db)\n",
    "\n",
    "    st.chat_message(\"assistant\").write(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0b3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11018fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b9eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75fe01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
